---
title: "EPIC Orientation 2018: Introduction to R"
date: "Updated: `r format(Sys.Date(), format = '%d %B %Y')`" 
output:
  html_document:
    theme: default
    highlight: zenburn
  md_document: default
  variant: markdown_github
github_document: default
number_sections: true
---

## Overview
1. Importing data
2. R Data Types
3. Working with dataframes
4. Data Manipulation with dplyr 
5. Reshaping data with tidyr
6. Vectorized functions 
7. Data Visualization using ggplot2
8. Fitting Linear Models
9. data.table

## 1. Importing data
For starters, we will be working with `tv_hurricanes_by_network.csv`, which contains the percentage of TV news that mention Hurricanes Harvey, Irma, Jose, and Maria each day.

Source: https://github.com/fivethirtyeight/data/tree/master/puerto-rico-media

Let's get started.
```{r}
#clean environment
rm(list = ls())

#to get current working directory
getwd() 

#to get help for a function
#Method 1:
help("read.csv") 
#Method 2:
?"read.csv"

#import csv
df <- read.csv("datasets/tv_hurricanes_by_network.csv")
```

R also has the capability to import other file formats including Stata, SPSS, SAS and Excel files using functions such as `read.spss()`, `read.dta()`, and `read.xport()`. You may wish to explore the `foreign` package to find out more. 

## 2. R Data Types

You will encounter a variety of data structures in R:

* #### vector
    + a one-dimensional array
    + elements of a vector must be of the same type
      + `numeric <- c(0.1, 2.2. 4.678)`
      + `integer <- c(5, 10, 100)`
      + `character <- c("EPIC", "is", "epic!")`
      + `logical <- c(T, F, T, T)`
* #### factors
    + special vectors that contain categorical values 
    + nominal values as a vector of integers and an internal vector of character strings mapped to these integers
* #### matrix
    + a special type of vector which has multiple dimensions 
    + all columns in a matrix must be of the same type (numeric, character, etc.) and the same length
* #### dataframe
    + more general than a matrix, different columns can have different modes (numeric, character, factor, etc.)
* #### list
    + an ordered collection of objects (components), a list allows you to gather (possibly unrelated) objects under one name (e.g. a string, a numeric vector, a matrix, and a scalar)  e.g. `mylist <- list("Hello", c(1,2,5.3,6,-2,4), matrix(1:20, nrow=5,ncol=4), 9)`
    + you can also make lists of lists e.g. `mylist <- list(list1, list2, list3)`

Let's examine our data.

```{r}
#see structure of object
str(df)
```

```{r}
#see class of a variable
class(df$Query)
```

R is currently treating the Query variable as nominal, let's change it to a character type.
```{r}
#change Query variable to a character type
df$Query <- as.character(df$Query) 
#see structure
str(df)
```

## 3. Working with Dataframes
Sometimes we deal with large dataframes and we don't always get the luxury of viewing it in its entirety. Instead, we can use the following functions:
```{r}
#see dimensions (in this order: row, column)
dim(df)
#view the first 2 obs
head(df, 2)
#view the last 3 obs
tail(df, 3)
#summary statistics
summary(df)
```

To access specific columns or rows by name or index:
```{r}
#Get the 2nd observation of the Query Variable
df[2, 'Query'] #Method 1
df$Query[2] #Method 2
#Get the 3rd observation of the 5th variable
df[3,5]
#Grab multiple elements (from the 1st & 2nd rows, 4th & 5th columns)
df[c(1,2), c(4,5)]
```


You can also perform functions or use operators on vectors
```{r}
#Find the minimum value of CNN
min(df$CNN) 
#Sum of all obs in BBC.News
sum(df$BBC.News)
#Standard deviation of Fox News
sd(df$FOX.News)
#Multiple CNN by 2
df$CNN.times.2 <- df$CNN*2
#Remove this newly created column
df$CNN.times.2 <- NULL
#Add variables together
df$CNN.plus.BBC <- df$CNN + df$BBC.News
#Convert Date variable from Factor to Date format
df$Date <- as.Date(df$Date, format = "%m/%d/%y")
#Tabulate the Query variable, how many observations are Hurricane Irma?
table(df$Query)
```

There are several ways to rename a column. For instance, if we'd like to rename the "Query"" column to "Hurricane"
```{r}
#view all variable names in df
names(df)
#Method 1: rename the second variable, aka Query
names(df)[2] <- "HURRICANE" #Method 1
#Method 2: rename based on the name
names(df)[names(df)=="HURRICANE"] <- "Hurricane"
#view all variable names in df again
names(df)
#Method 3: use rename() from the dplyr package which we will cover later
```

### Quiz 1: 
Create a numeric variable that assigns the following damage costs to each of the hurricanes. Name this variable `Costs` and use millions as the unit. 

* Harvey: $125Bn
* Maria: $90Bn
* Irma: $64.8Bn
* Jose: $2.8M

##### *“If you look for it, I've got a sneaky feeling you'll find that love actually is all around.” - Prime Minister David (Hugh Grant)*

```{r}
df$Costs[df$Hurricane=="Hurricane Harvey"] <- 125 * 1000
df$Costs[df$Hurricane=="Hurricane Irma"] <- 64.8 * 1000
df$Costs[df$Hurricane=="Hurricane Maria"] <- 90 * 1000
df$Costs[df$Hurricane=="Hurricane Jose"] <- 2.8
```

## 4. Data Manipulation with dplyr 

#### What's dplyr?
dplyr is a powerful package written by the amazing Hadley Wickham. It provides some easy-to-use functions for data analysis and manipulation.

```{r}
#install package
#install.packages("dplyr")
#load this package in your R environment
library(dplyr)
```

Now let's try out some of the most commonly-used functions.

* `select()` - select specific columns 
* `mutate()` - create a new column
* `rename()` - rename columns 
* `filter()` - select rows using a criteria
* `arrange()` - arrange rows
* `group_by()` - group data
* `summarise()` - summarize values

`select()` allows you to select specific columns from your dataframe.

```{r}
#select just the Date and CNN columns and display the first 3 observations
#my R is buggy but you should be able to run just this: head(select(df, Date, CNN))
head(dplyr::select(df, Date, CNN), 3)
```
`mutate()` allows you to create new variables

```{r}
#create a new column called BBC.and.CNN and display just the first 3 rows
head(mutate(df, BBC.and.CNN=BBC.News+CNN), 3)
```
`rename()` allows you to rename variables.
```{r}
#change the variable name BBC.News to just BBC and FOX.News to just FOX
#again, my R is buggy but you should be able to run just this: head(rename(df, c("BBC.News" = "BBC", "FOX.News" = "FOX")),3)
head(plyr::rename(df, c("BBC.News" = "BBC", "FOX.News" = "FOX")),3)
```

`filter()` allows you to select specific observations using conditions
```{r}
#find the first 3 observations where CNN has a value of < 0.1 and MSNBC < 0.02
head(filter(df, CNN < 0.1 & MSNBC < 0.02),3)
```

`arrange()` allows you to rearrange rows 
```{r}
#arrange rows according to Dates (in ascending order), then Hurricane
head(arrange(df, Date, Hurricane), 3)
```

`group_by()` uses a **split-apply-combine** concept. To break it down, we want to **split** the dataframe into groups by some variable you've specified, **apply** a function to these groups, and **combine** them again. Let's try this with the `summarise()` function.

```{r}
#Find out the mean news coverage in CNN by hurricane groups
df %>%
  group_by(Hurricane) %>%
  summarise(mean.coverage = mean(CNN))
```

#### What is this `%>%` symbol?
This is known as a **pipe operator**, which allows you to pipe the output from one function to the input of another function. This saves you from long, nested operations or doing a bunch of assignments. 

Without the pipe operator, you could also execute the previous script with a long, nested operation (too confusing):
```{r}
summarise(group_by(df, Hurricane), mean.coverage = mean(CNN))
```

Or using multiple assignments (too tedious):
```{r}
test <- group_by(df, Hurricane)
test <- summarise(test, mean.coverage = mean(CNN))
```

### Quiz 2: 
Using a combination of the functions we've covered, find out the average coverage of MSNBC for each hurricane, only include hurricanes where damage costs were above 10 million. Remember to use the pipe operator :D

```{r}
df %>%
  filter(Costs > 10) %>%
  group_by(Hurricane) %>%
  summarise(max.coverage = max(MSNBC)) %>%
  arrange(max.coverage)
  
```

Just to make a point, if you **didn't** use the pipe operator, a nested operation would have looked like this (don't do it).
```{r}
arrange(summarise(group_by(filter(df, Costs > 10), Hurricane), max.coverage = max(MSNBC)), max.coverage)
```

## 5. Reshaping data with tidyr 

#### What's tidyr?
The most commonly used functions in this package are `gather()` and `spread()`, which help us reshape our data. Our data currently has 4 separate columns for news coverage, one for each TV station. What if we wanted to restructure our data from a **wide to long** format, so the data of all 4 TV stations can be in a single variable?

```{r}
#install.packages("tidyr")
library(tidyr)
#reshape from wide to long
plot_df <- gather(df, 
        key = "tv.station", #name of the new column of 'old columns to be gathered'
        value = "coverage", #name of the 'gathered values' 
        BBC.News:MSNBC) #columns to be 'gathered'
```

`spread()` is the complement of the above. Try it out!
```{r}
#reshape from long to wide
head(spread(plot_df, tv.station, coverage), 3)
```

## 6. Vectorized functions 
The magic of R is that functions can work **element-wise** on vectors. Imagine we had a vector which contains a sequence of numbers from 1 to 10 million, let's call this variable `test_var`. 
```{r}
#create a vector called test_var which contains a sequence of numbers from 1 to 10 million
test_var <- seq(1, 1000000, 1)
head(test_var)
#check if it is a vector
is.vector(test_var)
```
Now imagine we wanted to square every number in this sequence and put it in a new variable called `test_var2`. A 'brute force' method might be to create a for loop:
```{r}
#create a new variable called test_var2
test_var2 <- test_var
#start the clock
time_forloop <- proc.time()
#loop through each element in test_var and square it
for (i in test_var) {
  test_var2[i] <- i^2 
}
#stop the clock
proc.time() - time_forloop
```
Now let's try it the R way
```{r}
#start the clock
time_vectorized <- proc.time()
#apply it to the vector
test_var2 <- test_var^2
#stop the clock
proc.time() - time_vectorized
```
This is all great for **vectors**, but can we do this for **lists**? 
```{r}
#create a list called test_var which contains a sequence of numbers from 1 to 10 million
test_var <- as.list(seq(1, 1000000, 1))
#preview list
head(test_var, 3)
#check if it is a list
is.list(test_var)
```
Now let's try squaring each element in the list like how we did earlier.
```{r}
#try 'squaring' the list
#test_var2 <- test_var^2
```
Looks like it doesn't quite work for lists, but that's okay! We can use the function called `map()` under the `purrr` package, which 'maps' a function over a list or vector **element-wise**, and returns a list as the output (the closest base R equivalent is `lapply`). First, let's create a function called `temp.convert()` that converts temperature from Celsius to Fahrenheit.
```{r}
#create function called temp.convert()
temp.convert <- function(temp.C) {
  temp.F <- temp.C*1.8 + 32
  print(paste0(temp.C, "C is equivalent to ", temp.F, "F"))
}
```
Now let's create a **list** of temperatures in Celsius.
```{r}
#create a list of temperatures in celsius
temp.list <- list(30, 20, 39, 10, -1, -7, -8, -9)
```
Now let's apply the `temp.convert()` function we created to the list of temperatures.
```{r}
#install.packages("purrr")
library(purrr)
#use map function to 'map' temp.convert() over temp.list
temps.converted <- map(.x = temp.list, .f = temp.convert)
#what type of object is temps.converted?
class(temps.converted)
```
For fun, let's try the `map()` function on a **vector** of temperatures.
```{r}
#create a vector of temperatures in celsius
temp.vector <- c(30, 20, 39, 10, -1, -7, -8, -9)
#map temp.convert() over temp.vector
temps.converted2 <- map_chr(.x = temp.vector, .f = temp.convert)
#check if temps.converted2 is a list
is.list(temps.converted2)
#check if temps.converted2 is a vector
is.vector(temps.converted2)
#what type of vector is temps.converted2?
class(temps.converted2)
```
Variants of `map()` are `map_lgl()`, `map_int()`, `map_dbl()` and `map_chr()` which return **vectors** of the corresponding type. To return dataframes, one can use `map_dfr()` and `map_dfc()`. When given a list of vectors, either function binds the vectors into a data frame by rows or columns. Remember that these last 2 variants require the `dplyr` package to work.

## 7. Data visualization with ggplot2 
The `ggplot2` package is based on the **grammar of graphics**, the idea that you can build every graph from the same few components: a data set, a set of geoms (data points), and a coordinate system.

```{r}
#install.packages ("ggplot2")
#install.packages ("scales")
library(ggplot2) 
library(scales)

#view dataframe for plotting 
head(plot_df)

#create density plots  
ggplot(data = plot_df) +
  geom_density(aes(x = coverage, fill = tv.station), alpha = 0.3) +
  theme_classic()  +
  xlab("news coverage")  #label the x axis

#create a timeseries of news coverage 
ggplot(data = plot_df) +
  geom_line(aes(x = as.Date(Date, "%m/%d/%y"), y = coverage, 
                group = tv.station, 
                color = tv.station), alpha = 0.7) +
  xlab("date") + 
  scale_x_date(labels = date_format("%m/%d"),
               breaks = date_breaks("1 week"))   +
  theme_classic()

#we could also have separate plots by tv station by using facet_wrap()
ggplot(data = plot_df) +
  geom_line(aes(x = as.Date(Date, "%m/%d/%y"), y = coverage, 
                group = tv.station, 
                color = tv.station), alpha = 0.5) +
  facet_wrap(~tv.station, ncol = 4) + 
  xlab("date") + 
  scale_x_date(labels = date_format("%m/%d"),
               breaks = date_breaks("2 weeks"))   +
  theme_classic()

#create histograms of each hurricane in terms of number of observations
ggplot(data = plot_df) +
  geom_bar(aes(x = Hurricane, fill = Hurricane), 
           color = "black",
           stat = "count", #calculates the number of cases in each group
           alpha = 0.3)  +
  theme_classic()

#create scatterplot of news coverage against time by TV Station
ggplot(data = plot_df) +
  geom_point(aes(y = coverage, x = as.Date(Date, "%m/%d/%y"), color = tv.station),
             shape = 16,
             size = 4,
             alpha = 0.3) + 
  xlab("date") +  
  theme_classic() +
  scale_x_date(labels = date_format("%m/%d"),
               breaks = date_breaks("1 week")) 

```

You may need to overlay plots sometimes, you can do this via layers, remember that they need to share common x and y axes.
```{r}
#overlay scatterplot on timeseries lineplot
ggplot(data = plot_df) +
  geom_line(aes(x = as.Date(Date, "%m/%d/%y"), y = coverage, 
                group = tv.station, 
                color = tv.station), alpha = 0.7) +
  geom_point(aes(y = coverage, x = as.Date(Date, "%m/%d/%y"), color = tv.station),
             shape = 16,
             size = 4,
             alpha = 0.3) + 
  xlab("date") + 
  theme_classic() +
  scale_x_date(labels = date_format("%m/%d"),
               breaks = date_breaks("1 week")) 

```

## 8. Fitting Linear Models 

Assuming in a bizarre world, we want to find out if MSNBC media coverage has an effect on CNN media coverage
```{r}
#regress CNN on MSNBC 
model <- lm(CNN ~ MSNBC, data = df)
summary(model)
```
Assuming we'd like to run another model that adds hurricane fixed effects
```{r}
library(lfe)
model2 <- felm(CNN ~ MSNBC | as.factor(Hurricane), data = df)
summary(model2)
```

## 9. data.table

`data.table` is a package is used for working with tabular data in R. It provides the efficient `data.table` object which is a much improved version of the default `data.frame`. The reason it’s popular is because of the speed of execution on larger data and the terse syntax. So, effectively you type less code and get much faster speed. The downside is that it may take longer time for others or even yourself to understand what the code is doing, so please make sure to comment enough on the code.

```{r}
#install package
#install.packages("data.table")
#load this package in your R environment
library(data.table)
```

To import data, you can use `fread()`, which is short for `fast read` as `data.table`'s `read.csv()`. It's at least 20 times faster. To see this, let's create a large CSV file and compare the speed of `fread()` and `read.csv()`. The time difference gets wider when the filesize increases.
```{r}
# Create a large .csv file
set.seed(100)
m <- data.frame(matrix(runif(10000000), nrow=1000000))
write.csv(m, 'trial_csv.csv', row.names = F)

# Time taken by read.csv to import
system.time({m_df <- read.csv('trial_csv.csv')})


# Time taken by fread to import
system.time({m_dt <- fread('trial_csv.csv')})

```

Next, to convert any dataframe to `data.table`, you can use `as.data.table(df)` or `setDT(df)`. The first one creates a copy of `df` and convert it to a `data.table`, whereas the second one convert the `df` directly, and no assignment is needed. To demonstrate features of `data.table`, let's use `mtcars` dataframe from R's default `datasets` package.

**Important**: The `data.table()` does not have any rownames. So if the `data.frame` has any rownames, you need to store it as a separate column before converting to `data.table`.

```{r}
# Load mtcars data
data("mtcars")
class(mtcars)
mtcars$carname <- rownames(mtcars)

# First method
mtcars_dt <- as.data.table(mtcars)
class(mtcars_dt)
head(mtcars_dt)

# Second method
mtcars_copy <- copy(mtcars)
setDT(mtcars_copy)
class(mtcars_copy)
head(mtcars_copy)
```

To subset rows based on conditions, the main difference with dataframe is: `data.table` is aware of its column names. So while filtering, passing only the columns names inside the square brackets is sufficient.
```{r}
# dataframe syntax
mtcars[mtcars$cyl == 6 & mtcars$gear == 4, ]

# datatable syntax
mtcars_dt[cyl==6 & gear==4, ]
```

To subset columns, you can either use the column name, or the column number.
```{r}
mtcars_dt[, 1]

mtcars_dt[, 3:5]

mtcars_dt[, "mpg"]

mtcars_dt[, c("mpg", "hp", "wt")]


```

To drop columns, simply place them in a vector and use `!` in front to drop.

```{r}
drop_cols <- c("mpg", "cyl", "gear")
mtcars_dt[, !drop_cols, with = FALSE]
```

To rename columns, use `setnames`.
```{r}
colnames(mtcars_dt)
setnames(mtcars_dt, 'vs', 'engine_type')
colnames(mtcars_dt)
```

To create new columns from exising columns, it's easier to just use the square brackets. And if you need to create multiple columns, you can use the special assignment symbol `:=` as a function.
```{r}
# data.frame syntax (works on data.table)
mtcars_dt$cyl_gear <- mtcars_dt$cyl + mtcars_dt$gear

# data.table syntax
mtcars_dt[, cyl_gear2 := cyl + gear]


# multiple columns
mtcars_dt[,  `:=` (cyl_gear3 = cyl * gear,
                   cyl_gear4 = cyl - gear)]
mtcars_dt
```

Now, let’s move on to the second major and awesome feature of R data.table: grouping using by.

In base R, grouping is accomplished using the `aggregate()` function. It’s a bit cumbersome and hard to remember the syntax. All the functionalities can be accomplished easily using the ‘by’ argument within square brackets.

For example, in `mtcars` data, how to get the mean mileage for each cylinder type?

Answer: Since you want to see the mileage by `cyl` column, set `by = 'cyl'` inside the square brackets. And you can even add multiple columns to the 'by' argument.
```{r}
# Mean mileage by `cyl` 
mtcars_dt[, .(mean_mileage=mean(mpg)), by=cyl]

# Mean mileage by 'cyl' and 'gear'
mtcars_dt[, .(mean_mileage=mean(mpg)), by=.(cyl, gear)]
```

Next, let's introduce `.N` and `.I`. `.N` contains the number of rows present. `.I` returns simply the row number. You may want to use `seq_len(.N)` when trying to create row number when grouping.
```{r}

mtcars_dt[, cyl_count := .N, by = cyl]

mtcars_dt[, row_index := .I]

mtcars_dt[, cyl_row_index := seq_len(.N), by = cyl]

mtcars_dt[order(cyl),]
```

Now let's talk about "chaining", which makes `data.table` even more powerful and great for data manipulation. Using chaining, you can do multiple datatable operatations one after the other without having to store intermediate results.

For example, instead of writing two statements you can do it on one.

Below code sorts after grouping by cyl:
```{r}
dt1 <- mtcars_dt[, .(mean_mpg=mean(mpg),
                     mean_disp=mean(disp),
                     mean_wt=mean(wt),
                     mean_qsec=mean(qsec)), by=cyl]
output <- dt1[order(cyl), ]
output
```

With chaining, that is, by attaching the square brackets at the end, it’s done in one step.
```{r}
output <- mtcars_dt[, .(mean_mpg=mean(mpg),
                        mean_disp=mean(disp),
                        mean_wt=mean(wt),
                        mean_qsec=mean(qsec)), by=cyl][
                    order(cyl), ]
```

And with chaining, you can easily create new columns using previous columns and play with the data faster.

Second to last, `data.table` allows you to write functions within the brackets. Let’s suppose, you want to compute the mean of all the variables, grouped by ‘cyl’. You can create the columns one by one by writing by hand. Or, you can use the `lapply()` function to do it all in one go.

But `lapply()` takes the data.frame as the first argument. You can use the `.SD` object as the first argument for `lapply()`. The `.SD` object is nothing but a data.table that contains all the columns of the original datatable except the column specified in ‘by’ argument. So, here is what it looks like.
```{r}
mtcars_dt[, .SD, by=cyl]
```
So, now you can pass this as the first argument in `lapply()`. The 11th column in `.SD` is rownames, so let’s include only the first 10.
```{r}
output <- mtcars_dt[, lapply(.SD[, 1:10, with=F], mean), by=cyl]
output
```

At last, let's talk about keys in `data.table`. You can set one or more keys on a DT to perform binary search, which is very faster than linear search, especially for large data. As a result, the filtering operations are super fast after setting the keys. There is a side effect though. By setting a key, the `data.table` gets sorted by that key. Here we are going to use `setkey` function.

```{r}
setkey(mtcars_dt, carname)

# mtcars_dt is sorted by carname now
mtcars_dt

# check keys for a data.table
key(mtcars_dt)
```

Once the key is set, merging data.tables is very direct. I have distributed few columns of mtcars in the following data.tables.
```{r}
dt1 <- mtcars_dt[,.(carname, mpg, cyl)]
dt2 <- mtcars_dt[1:10, .(carname, gear)]
```
You can join these two datatables. Note the difference between the ordering. More information regarding merge/join using data.table can be found [here](https://rstudio-pubs-static.s3.amazonaws.com/52230_5ae0d25125b544caab32f75f0360e775.html).
```{r}
join_1 <- dt1[dt2]
join_2 <- dt2[dt1]

join_1
join_2

nrow(join_1)
nrow(dt2)
nrow(join_2)
nrow(dt1)

```



#### More Helpful Links
* https://github.com/yixinsun1216/covertoperations_manual/wiki/R-Guide 
* https://tutorials.iq.harvard.edu/R/Rstatistics/Rstatistics.html
* http://genomicsclass.github.io/book/pages/dplyr_tutorial.html
* https://cran.r-project.org/web/packages/dplyr/vignettes/dplyr.html
* https://tutorials.iq.harvard.edu/R/Rgraphics/Rgraphics.html
* https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html
* https://www.machinelearningplus.com/data-manipulation/datatable-in-r-complete-guide/

